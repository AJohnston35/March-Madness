{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        region          round             team1  seed1  score1         team2  \\\n",
      "0         East    First Round             UConn      1      91       Stetson   \n",
      "1         East    First Round  Florida Atlantic      8      65  Northwestern   \n",
      "2         East    First Round   San Diego State      5      69           UAB   \n",
      "3         East    First Round            Auburn      4      76          Yale   \n",
      "4         East    First Round               BYU      6      67      Duquesne   \n",
      "...        ...            ...               ...    ...     ...           ...   \n",
      "1984      West  Sweet Sixteen          NC State      3      61       Alabama   \n",
      "1985      West    Elite Eight   St. John's (NY)      1      69      NC State   \n",
      "1986  National     Final Four         Villanova      8      52       Memphis   \n",
      "1987  National     Final Four   St. John's (NY)      1      59    Georgetown   \n",
      "1988  National   Championship         Villanova      8      66    Georgetown   \n",
      "\n",
      "      seed2  score2           winner  year  \n",
      "0        16      52            UConn  2024  \n",
      "1         9      77     Northwestern  2024  \n",
      "2        12      65  San Diego State  2024  \n",
      "3        13      78             Yale  2024  \n",
      "4        11      71         Duquesne  2024  \n",
      "...     ...     ...              ...   ...  \n",
      "1984      7      55         NC State  1985  \n",
      "1985      3      60  St. John's (NY)  1985  \n",
      "1986      2      45        Villanova  1985  \n",
      "1987      1      77       Georgetown  1985  \n",
      "1988      1      64        Villanova  1985  \n",
      "\n",
      "[1989 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize empty list to store dataframes\n",
    "tournament_dfs = []\n",
    "\n",
    "# Get all tournament files from 2024 back to 1985\n",
    "for year in range(2024, 1984, -1):\n",
    "    filename = f\"tournament_games_{year}.csv\"\n",
    "    file_path = Path(\"tournament_history\") / filename\n",
    "    \n",
    "    if file_path.exists():\n",
    "        # Read CSV and add year identifier\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['year'] = year\n",
    "        tournament_dfs.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "all_tournaments = pd.concat(tournament_dfs, ignore_index=True)\n",
    "\n",
    "print(all_tournaments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rk                  School      Conf   W   L   Pts   Opp    MOV  \\\n",
      "0        1             Connecticut  Big East  37   3  81.4  63.4  18.00   \n",
      "1        2                 Houston    Big 12  32   5  73.5  57.6  15.89   \n",
      "2        3                  Purdue   Big Ten  34   5  82.3  69.0  13.33   \n",
      "3        4                 Arizona    Pac-12  27   9  87.1  72.1  15.08   \n",
      "4        5                  Auburn       SEC  27   8  83.1  68.3  14.80   \n",
      "...    ...                     ...       ...  ..  ..   ...   ...    ...   \n",
      "12950  278           Georgia State      TAAC   2  26  66.4  83.8 -17.32   \n",
      "12951  279         Bethune-Cookman      MEAC   8  19  67.7  78.6 -10.93   \n",
      "12952  280  Maryland-Eastern Shore      MEAC   3  25  60.5  76.6 -16.07   \n",
      "12953  281            Morgan State      MEAC   3  25  67.7  91.4 -23.68   \n",
      "12954  282      U.S. International       Ind   1  27  54.9  82.8 -27.93   \n",
      "\n",
      "         SOS   OSRS   DSRS    SRS    ORtg   DRtg   NRtg  year  \n",
      "0       8.70  12.04  14.67  26.70  127.65  89.05  38.60  2024  \n",
      "1       9.80   6.19  19.50  25.69  120.40  81.96  38.45  2024  \n",
      "2      11.60  14.65  10.29  24.93  126.62  91.31  35.31  2024  \n",
      "3       9.45  18.59   5.95  24.54  122.12  89.17  32.95  2024  \n",
      "4       7.66  13.48   8.98  22.46  121.57  90.09  31.48  2024  \n",
      "...      ...    ...    ...    ...     ...    ...    ...   ...  \n",
      "12950  -3.84  -5.42 -16.93 -22.34     NaN    NaN    NaN  1985  \n",
      "12951 -11.05  -8.45 -15.37 -23.81     NaN    NaN    NaN  1985  \n",
      "12952  -9.55 -14.69 -12.98 -27.67     NaN    NaN    NaN  1985  \n",
      "12953  -6.78  -3.51 -26.50 -30.01     NaN    NaN    NaN  1985  \n",
      "12954  -2.60 -17.32 -14.41 -31.72     NaN    NaN    NaN  1985  \n",
      "\n",
      "[12955 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list to store ratings dataframes\n",
    "ratings_dfs = []\n",
    "\n",
    "# Get all ratings files from 2024 back to 1985\n",
    "for year in range(2024, 1984, -1):\n",
    "    filename = f\"ratings_{year}.csv\"\n",
    "    file_path = Path(\"team_ratings\") / filename\n",
    "    \n",
    "    if file_path.exists():\n",
    "        # Read CSV and add year identifier\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['year'] = year\n",
    "        ratings_dfs.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "all_ratings = pd.concat(ratings_dfs, ignore_index=True)\n",
    "\n",
    "# Drop any columns that start with 'Unnamed'\n",
    "unnamed_cols = [col for col in all_ratings.columns if col.startswith('Unnamed')]\n",
    "all_ratings = all_ratings.drop(columns=unnamed_cols)\n",
    "\n",
    "\n",
    "print(all_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rk', 'school', 'g', 'w', 'l', 'w-l%', 'srs', 'sos', 'unnamed: 8',\n",
      "       'conf_w', 'conf_l', 'unnamed: 11', 'home_w', 'home_l', 'unnamed: 14',\n",
      "       'away_w', 'away_l', 'unnamed: 17', 'tm.', 'opp.', 'unnamed: 20', 'mp',\n",
      "       'fg', 'fga', 'fg%', '3p', '3pa', '3p%', 'ft', 'fta', 'ft%', 'orb',\n",
      "       'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'year'],\n",
      "      dtype='object') Index(['rk', 'school', 'g', 'w', 'l', 'w-l%', 'srs', 'sos', 'conf_w', 'conf_l',\n",
      "       'home_w', 'home_l', 'away_w', 'away_l', 'tm.', 'opp.', 'mp', 'opp_fg',\n",
      "       'opp_fga', 'opp_fg%', 'opp_3p', 'opp_3pa', 'opp_3p%', 'opp_ft',\n",
      "       'opp_fta', 'opp_ft%', 'opp_orb', 'opp_trb', 'opp_ast', 'opp_stl',\n",
      "       'opp_blk', 'opp_tov', 'opp_pf', 'year'],\n",
      "      dtype='object')\n",
      "Basic stats shape: (10702, 71)\n",
      "Advanced stats shape: (10702, 68)\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists for each file type\n",
    "basic_dfs = []\n",
    "basic_opp_dfs = []\n",
    "adv_dfs = []\n",
    "adv_opp_dfs = []\n",
    "\n",
    "# Get basic stats files\n",
    "for year in range(2024, 1984, -1):\n",
    "    basic_file = Path(\"school_stats/old\") / f\"basic_{year}.csv\"\n",
    "    basic_opp_file = Path(\"school_stats/old\") / f\"basic_opp_{year}.csv\"\n",
    "    adv_file = Path(\"school_stats/old\") / f\"adv_{year}.csv\"\n",
    "    adv_opp_file = Path(\"school_stats/old\") / f\"adv_opp_{year}.csv\"\n",
    "    \n",
    "    if basic_file.exists():\n",
    "        # Read CSV directly\n",
    "        df = pd.read_csv(basic_file)\n",
    "        df['year'] = year\n",
    "        basic_dfs.append(df)\n",
    "        \n",
    "    if basic_opp_file.exists():\n",
    "        # Read CSV directly\n",
    "        df = pd.read_csv(basic_opp_file)\n",
    "        df['year'] = year\n",
    "        # Add '_opp' suffix to stat columns\n",
    "        stat_cols = [col for col in df.columns if col not in ['School', 'year']]\n",
    "\n",
    "        basic_opp_dfs.append(df)\n",
    "        \n",
    "    if adv_file.exists():\n",
    "        # Read CSV directly\n",
    "        df = pd.read_csv(adv_file)\n",
    "        df['year'] = year\n",
    "        adv_dfs.append(df)\n",
    "        \n",
    "    if adv_opp_file.exists():\n",
    "        # Read CSV directly\n",
    "        df = pd.read_csv(adv_opp_file)\n",
    "        df['year'] = year\n",
    "        # Add '_opp' suffix to stat columns\n",
    "        stat_cols = [col for col in df.columns if col not in ['School', 'year']]\n",
    "        adv_opp_dfs.append(df)\n",
    "\n",
    "# Combine all basic stats\n",
    "all_basic = pd.concat(basic_dfs, ignore_index=True)\n",
    "all_basic_opp = pd.concat(basic_opp_dfs, ignore_index=True)\n",
    "\n",
    "# Convert column names to lowercase\n",
    "all_basic.columns = all_basic.columns.str.lower()\n",
    "all_basic_opp.columns = all_basic_opp.columns.str.lower()\n",
    "\n",
    "print(all_basic.columns, all_basic_opp.columns)\n",
    "\n",
    "# Merge basic and basic opponent stats\n",
    "basic_merged = pd.merge(all_basic, all_basic_opp, on=['school', 'year'], how='outer')\n",
    "\n",
    "# Combine all advanced stats\n",
    "all_adv = pd.concat(adv_dfs, ignore_index=True)\n",
    "all_adv_opp = pd.concat(adv_opp_dfs, ignore_index=True)\n",
    "\n",
    "# Convert column names to lowercase\n",
    "all_adv.columns = all_adv.columns.str.lower()\n",
    "all_adv_opp.columns = all_adv_opp.columns.str.lower()\n",
    "\n",
    "# Merge advanced and advanced opponent stats\n",
    "adv_merged = pd.merge(all_adv, all_adv_opp, on=['school', 'year'], how='outer')\n",
    "\n",
    "print(\"Basic stats shape:\", basic_merged.shape)\n",
    "print(\"Advanced stats shape:\", adv_merged.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Folder containing .xls files (which are actually HTML format) within school_stats folder\n",
    "folder_path = \"school_stats/*.xls\"\n",
    "\n",
    "# Loop through all .xls files and convert them to .csv\n",
    "for file in glob.glob(folder_path):\n",
    "    try:\n",
    "        # Read the file as HTML\n",
    "        tables = pd.read_html(file)  # Returns a list of tables\n",
    "        for i, df in enumerate(tables):\n",
    "            csv_filename = file.replace(\".xls\", f\"_{i}.csv\").replace(\"school_stats/\", \"school_stats/\")  # Handle multiple tables\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Converted {file} -> {csv_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed adv_2002_0.csv to adv_2002.csv\n",
      "Renamed adv_2003_0.csv to adv_2003.csv\n",
      "Renamed adv_2004_0.csv to adv_2004.csv\n",
      "Renamed adv_2005_0.csv to adv_2005.csv\n",
      "Renamed adv_2006_0.csv to adv_2006.csv\n",
      "Renamed adv_2007_0.csv to adv_2007.csv\n",
      "Renamed adv_2008_0.csv to adv_2008.csv\n",
      "Renamed adv_2009_0.csv to adv_2009.csv\n",
      "Renamed adv_2010_0.csv to adv_2010.csv\n",
      "Renamed adv_2011_0.csv to adv_2011.csv\n",
      "Renamed adv_2012_0.csv to adv_2012.csv\n",
      "Renamed adv_2013_0.csv to adv_2013.csv\n",
      "Renamed adv_2014_0.csv to adv_2014.csv\n",
      "Renamed adv_2015_0.csv to adv_2015.csv\n",
      "Renamed adv_2016_0.csv to adv_2016.csv\n",
      "Renamed adv_2017_0.csv to adv_2017.csv\n",
      "Renamed adv_2018_0.csv to adv_2018.csv\n",
      "Renamed adv_2019_0.csv to adv_2019.csv\n",
      "Renamed adv_2020_0.csv to adv_2020.csv\n",
      "Renamed adv_2021_0.csv to adv_2021.csv\n",
      "Renamed adv_2022_0.csv to adv_2022.csv\n",
      "Renamed adv_2023_0.csv to adv_2023.csv\n",
      "Renamed adv_2024_0.csv to adv_2024.csv\n",
      "Renamed adv_2025_0.csv to adv_2025.csv\n",
      "Renamed adv_opp_2010_0.csv to adv_opp_2010.csv\n",
      "Renamed adv_opp_2011_0.csv to adv_opp_2011.csv\n",
      "Renamed adv_opp_2012_0.csv to adv_opp_2012.csv\n",
      "Renamed adv_opp_2013_0.csv to adv_opp_2013.csv\n",
      "Renamed adv_opp_2014_0.csv to adv_opp_2014.csv\n",
      "Renamed adv_opp_2015_0.csv to adv_opp_2015.csv\n",
      "Renamed adv_opp_2016_0.csv to adv_opp_2016.csv\n",
      "Renamed adv_opp_2017_0.csv to adv_opp_2017.csv\n",
      "Renamed adv_opp_2018_0.csv to adv_opp_2018.csv\n",
      "Renamed adv_opp_2019_0.csv to adv_opp_2019.csv\n",
      "Renamed adv_opp_2020_0.csv to adv_opp_2020.csv\n",
      "Renamed adv_opp_2021_0.csv to adv_opp_2021.csv\n",
      "Renamed adv_opp_2022_0.csv to adv_opp_2022.csv\n",
      "Renamed adv_opp_2023_0.csv to adv_opp_2023.csv\n",
      "Renamed adv_opp_2024_0.csv to adv_opp_2024.csv\n",
      "Renamed adv_opp_2025_0.csv to adv_opp_2025.csv\n",
      "Renamed basic_1993_0.csv to basic_1993.csv\n",
      "Renamed basic_1994_0.csv to basic_1994.csv\n",
      "Renamed basic_1995_0.csv to basic_1995.csv\n",
      "Renamed basic_1996_0.csv to basic_1996.csv\n",
      "Renamed basic_1997_0.csv to basic_1997.csv\n",
      "Renamed basic_1998_0.csv to basic_1998.csv\n",
      "Renamed basic_1999_0.csv to basic_1999.csv\n",
      "Renamed basic_2000_0.csv to basic_2000.csv\n",
      "Renamed basic_2001_0.csv to basic_2001.csv\n",
      "Renamed basic_2002_0.csv to basic_2002.csv\n",
      "Renamed basic_2003_0.csv to basic_2003.csv\n",
      "Renamed basic_2004_0.csv to basic_2004.csv\n",
      "Renamed basic_2005_0.csv to basic_2005.csv\n",
      "Renamed basic_2006_0.csv to basic_2006.csv\n",
      "Renamed basic_2007_0.csv to basic_2007.csv\n",
      "Renamed basic_2008_0.csv to basic_2008.csv\n",
      "Renamed basic_2009_0.csv to basic_2009.csv\n",
      "Renamed basic_2010_0.csv to basic_2010.csv\n",
      "Renamed basic_2011_0.csv to basic_2011.csv\n",
      "Renamed basic_2012_0.csv to basic_2012.csv\n",
      "Renamed basic_2013_0.csv to basic_2013.csv\n",
      "Renamed basic_2014_0.csv to basic_2014.csv\n",
      "Renamed basic_2015_0.csv to basic_2015.csv\n",
      "Renamed basic_2016_0.csv to basic_2016.csv\n",
      "Renamed basic_2017_0.csv to basic_2017.csv\n",
      "Renamed basic_2018_0.csv to basic_2018.csv\n",
      "Renamed basic_2019_0.csv to basic_2019.csv\n",
      "Renamed basic_2020_0.csv to basic_2020.csv\n",
      "Renamed basic_2021_0.csv to basic_2021.csv\n",
      "Renamed basic_2022_0.csv to basic_2022.csv\n",
      "Renamed basic_2023_0.csv to basic_2023.csv\n",
      "Renamed basic_2024_0.csv to basic_2024.csv\n",
      "Renamed basic_2025_0.csv to basic_2025.csv\n",
      "Renamed basic_opp_2010_0.csv to basic_opp_2010.csv\n",
      "Renamed basic_opp_2011_0.csv to basic_opp_2011.csv\n",
      "Renamed basic_opp_2012_0.csv to basic_opp_2012.csv\n",
      "Renamed basic_opp_2013_0.csv to basic_opp_2013.csv\n",
      "Renamed basic_opp_2014_0.csv to basic_opp_2014.csv\n",
      "Renamed basic_opp_2015_0.csv to basic_opp_2015.csv\n",
      "Renamed basic_opp_2016_0.csv to basic_opp_2016.csv\n",
      "Renamed basic_opp_2017_0.csv to basic_opp_2017.csv\n",
      "Renamed basic_opp_2018_0.csv to basic_opp_2018.csv\n",
      "Renamed basic_opp_2019_0.csv to basic_opp_2019.csv\n",
      "Renamed basic_opp_2020_0.csv to basic_opp_2020.csv\n",
      "Renamed basic_opp_2021_0.csv to basic_opp_2021.csv\n",
      "Renamed basic_opp_2022_0.csv to basic_opp_2022.csv\n",
      "Renamed basic_opp_2023_0.csv to basic_opp_2023.csv\n",
      "Renamed basic_opp_2024_0.csv to basic_opp_2024.csv\n",
      "Renamed basic_opp_2025_0.csv to basic_opp_2025.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Rename files in the school_stats directory by removing '_0' from the filenames\n",
    "for file in os.listdir(\"school_stats\"):\n",
    "    if file.endswith(\"_0.csv\"):\n",
    "        new_file_name = file[:-6] + \".csv\"  # Remove '_0' and keep the .csv extension\n",
    "        os.rename(os.path.join(\"school_stats\", file), os.path.join(\"school_stats\", new_file_name))\n",
    "        print(f\"Renamed {file} to {new_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed school_stats/old\\basic_1993.csv\n",
      "Processed school_stats/old\\basic_1994.csv\n",
      "Processed school_stats/old\\basic_1995.csv\n",
      "Processed school_stats/old\\basic_1996.csv\n",
      "Processed school_stats/old\\basic_1997.csv\n",
      "Processed school_stats/old\\basic_1998.csv\n",
      "Processed school_stats/old\\basic_1999.csv\n",
      "Processed school_stats/old\\basic_2000.csv\n",
      "Processed school_stats/old\\basic_2001.csv\n",
      "Processed school_stats/old\\basic_2002.csv\n",
      "Processed school_stats/old\\basic_2003.csv\n",
      "Processed school_stats/old\\basic_2004.csv\n",
      "Processed school_stats/old\\basic_2005.csv\n",
      "Processed school_stats/old\\basic_2006.csv\n",
      "Processed school_stats/old\\basic_2007.csv\n",
      "Processed school_stats/old\\basic_2008.csv\n",
      "Processed school_stats/old\\basic_2009.csv\n",
      "Processed school_stats/old\\basic_2010.csv\n",
      "Processed school_stats/old\\basic_2011.csv\n",
      "Processed school_stats/old\\basic_2012.csv\n",
      "Processed school_stats/old\\basic_2013.csv\n",
      "Processed school_stats/old\\basic_2014.csv\n",
      "Processed school_stats/old\\basic_2015.csv\n",
      "Processed school_stats/old\\basic_2016.csv\n",
      "Processed school_stats/old\\basic_2017.csv\n",
      "Processed school_stats/old\\basic_2018.csv\n",
      "Processed school_stats/old\\basic_2019.csv\n",
      "Processed school_stats/old\\basic_2020.csv\n",
      "Processed school_stats/old\\basic_2021.csv\n",
      "Processed school_stats/old\\basic_2022.csv\n",
      "Processed school_stats/old\\basic_2023.csv\n",
      "Processed school_stats/old\\basic_2024.csv\n",
      "Processed school_stats/old\\basic_opp_2010.csv\n",
      "Processed school_stats/old\\basic_opp_2011.csv\n",
      "Processed school_stats/old\\basic_opp_2012.csv\n",
      "Processed school_stats/old\\basic_opp_2013.csv\n",
      "Processed school_stats/old\\basic_opp_2014.csv\n",
      "Processed school_stats/old\\basic_opp_2015.csv\n",
      "Processed school_stats/old\\basic_opp_2016.csv\n",
      "Processed school_stats/old\\basic_opp_2017.csv\n",
      "Processed school_stats/old\\basic_opp_2018.csv\n",
      "Processed school_stats/old\\basic_opp_2019.csv\n",
      "Processed school_stats/old\\basic_opp_2020.csv\n",
      "Processed school_stats/old\\basic_opp_2021.csv\n",
      "Processed school_stats/old\\basic_opp_2022.csv\n",
      "Processed school_stats/old\\basic_opp_2023.csv\n",
      "Processed school_stats/old\\basic_opp_2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Loop through all .csv files in the school_stats directory\n",
    "for file in glob.glob(\"school_stats/old/basic*.csv\"):\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        if len(df.columns) == 38:\n",
    "        # Rename the columns to the specified names\n",
    "            df.columns = ['Rk', 'School', 'G', 'W', 'L', 'W-L%', 'SRS', 'SOS', '', 'Conf_W', 'Conf_L', '', 'Home_W', 'Home_L', '', 'Away_W', 'Away_L', '', 'Tm.', 'Opp.', '', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF']\n",
    "        else: \n",
    "            df.columns = ['Rk', 'School', 'G', 'W', 'L', 'W-L%', 'SRS', 'SOS', 'Conf_W', 'Conf_L', 'Home_W', 'Home_L', 'Away_W', 'Away_L', 'Tm.', 'Opp.', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF']\n",
    "        \n",
    "        if \"basic_opp\" in file:\n",
    "            df.columns = ['Rk', 'School', 'G', 'W', 'L', 'W-L%', 'SRS', 'SOS', 'Conf_W', 'Conf_L', 'Home_W', 'Home_L', 'Away_W', 'Away_L', 'Tm.', 'Opp.', 'MP', 'Opp_FG', 'Opp_FGA', 'Opp_FG%', 'Opp_3P', 'Opp_3PA', 'Opp_3P%', 'Opp_FT', 'Opp_FTA', 'Opp_FT%', 'Opp_ORB', 'Opp_TRB', 'Opp_AST', 'Opp_STL', 'Opp_BLK', 'Opp_TOV', 'Opp_PF']\n",
    "\n",
    "        # Save the modified DataFrame back to CSV\n",
    "        df.to_csv(file, index=False)\n",
    "        print(f\"Processed {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed school_stats/old\\adv_1993.csv\n",
      "Processed school_stats/old\\adv_1994.csv\n",
      "Processed school_stats/old\\adv_1995.csv\n",
      "Processed school_stats/old\\adv_1996.csv\n",
      "Processed school_stats/old\\adv_1997.csv\n",
      "Processed school_stats/old\\adv_1998.csv\n",
      "Processed school_stats/old\\adv_1999.csv\n",
      "Processed school_stats/old\\adv_2000.csv\n",
      "Processed school_stats/old\\adv_2001.csv\n",
      "Processed school_stats/old\\adv_2002.csv\n",
      "Processed school_stats/old\\adv_2003.csv\n",
      "Processed school_stats/old\\adv_2004.csv\n",
      "Processed school_stats/old\\adv_2005.csv\n",
      "Processed school_stats/old\\adv_2006.csv\n",
      "Processed school_stats/old\\adv_2007.csv\n",
      "Processed school_stats/old\\adv_2008.csv\n",
      "Processed school_stats/old\\adv_2009.csv\n",
      "Processed school_stats/old\\adv_2010.csv\n",
      "Processed school_stats/old\\adv_2011.csv\n",
      "Processed school_stats/old\\adv_2012.csv\n",
      "Processed school_stats/old\\adv_2013.csv\n",
      "Processed school_stats/old\\adv_2014.csv\n",
      "Processed school_stats/old\\adv_2015.csv\n",
      "Processed school_stats/old\\adv_2016.csv\n",
      "Processed school_stats/old\\adv_2017.csv\n",
      "Processed school_stats/old\\adv_2018.csv\n",
      "Processed school_stats/old\\adv_2019.csv\n",
      "Processed school_stats/old\\adv_2020.csv\n",
      "Processed school_stats/old\\adv_2021.csv\n",
      "Processed school_stats/old\\adv_2022.csv\n",
      "Processed school_stats/old\\adv_2023.csv\n",
      "Processed school_stats/old\\adv_2024.csv\n",
      "Processed school_stats/old\\adv_opp_2010.csv\n",
      "Processed school_stats/old\\adv_opp_2011.csv\n",
      "Processed school_stats/old\\adv_opp_2012.csv\n",
      "Processed school_stats/old\\adv_opp_2013.csv\n",
      "Processed school_stats/old\\adv_opp_2014.csv\n",
      "Processed school_stats/old\\adv_opp_2015.csv\n",
      "Processed school_stats/old\\adv_opp_2016.csv\n",
      "Processed school_stats/old\\adv_opp_2017.csv\n",
      "Processed school_stats/old\\adv_opp_2018.csv\n",
      "Processed school_stats/old\\adv_opp_2019.csv\n",
      "Processed school_stats/old\\adv_opp_2020.csv\n",
      "Processed school_stats/old\\adv_opp_2021.csv\n",
      "Processed school_stats/old\\adv_opp_2022.csv\n",
      "Processed school_stats/old\\adv_opp_2023.csv\n",
      "Processed school_stats/old\\adv_opp_2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Loop through all .csv files in the school_stats directory for advanced stats\n",
    "for file in glob.glob(\"school_stats/old/adv_*.csv\"):\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "\n",
    "        if len(df.columns) == 34:\n",
    "        # Rename the columns to the specified names\n",
    "            df.columns = ['Rk', 'School', 'G', 'W', 'L', 'W-L%', 'SRS', 'SOS', '', 'Conf_W', 'Conf_L', '', 'Home_W', 'Home_L', '', 'Away_W', 'Away_L', '', 'Tm.', 'Opp.', '', 'Pace', 'ORtg', 'FTr', '3PAr', 'TS%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'eFG%', 'TOV%', 'ORB%', 'FT/FGA']\n",
    "        else:\n",
    "            df.columns = ['Rk', 'School', 'G', 'W', 'L', 'W-L%', 'SRS', 'SOS', 'Conf_W', 'Conf_L', 'Home_W', 'Home_L', 'Away_W', 'Away_L', 'Tm.', 'Opp.', 'Pace', 'ORtg', 'FTr', '3PAr', 'TS%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'eFG%', 'TOV%', 'ORB%', 'FT/FGA']\n",
    "        \n",
    "        if 'adv_opp' in file:\n",
    "            df.columns = ['Rk', 'School', 'G', 'W', 'L', 'W-L%', 'SRS', 'SOS', '', 'Conf_W', 'Conf_L', '', 'Home_W', 'Home_L', '', 'Away_W', 'Away_L', '', 'Tm.', 'Opp.', '', 'Opp_Pace', 'Opp_ORtg', 'Opp_FTr', 'Opp_3PAr', 'Opp_TS%', 'Opp_TRB%', 'Opp_AST%', 'Opp_STL%', 'Opp_BLK%', 'Opp_eFG%', 'Opp_TOV%', 'Opp_ORB%', 'Opp_FT/FGA']\n",
    "\n",
    "        # Save the modified DataFrame back to CSV\n",
    "        df.to_csv(file, index=False)\n",
    "        print(f\"Processed {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns ending with '_y' and columns starting with 'unnamed'\n",
    "adv_merged = adv_merged.loc[:, ~adv_merged.columns.str.endswith('_y')]\n",
    "adv_merged = adv_merged.loc[:, ~adv_merged.columns.str.startswith('unnamed')]\n",
    "\n",
    "# Remove '_x' from column names\n",
    "adv_merged.columns = adv_merged.columns.str.replace('_x', '', regex=False)\n",
    "\n",
    "# Drop columns ending with '_y' and columns starting with 'unnamed' for basic_merged\n",
    "basic_merged = basic_merged.loc[:, ~basic_merged.columns.str.endswith('_y')]\n",
    "basic_merged = basic_merged.loc[:, ~basic_merged.columns.str.startswith('unnamed')]\n",
    "\n",
    "# Remove '_x' from column names for basic_merged\n",
    "basic_merged.columns = basic_merged.columns.str.replace('_x', '', regex=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  rk             school   g   w   l   w-l%    srs   sos  conf_w  ...  \\\n",
      "0  2014   1  Abilene Christian  31  11  20  0.355 -19.60 -4.12     2.0  ...   \n",
      "1  2015   1  Abilene Christian  31  10  21  0.323 -17.20 -6.34     4.0  ...   \n",
      "2  2016   1  Abilene Christian  31  13  18  0.419 -13.93 -7.53     8.0  ...   \n",
      "3  2017   1  Abilene Christian  29  13  16  0.448 -11.86 -7.10     7.0  ...   \n",
      "4  2018   1  Abilene Christian  32  16  16  0.500  -9.14 -6.82     8.0  ...   \n",
      "5  2020   1  Abilene Christian  31  20  11  0.645  -2.87 -6.87    15.0  ...   \n",
      "6  2022   1  Abilene Christian  36  25  11  0.694   2.25 -2.09    11.0  ...   \n",
      "7  2023   1  Abilene Christian  30  13  17  0.433  -2.79  0.90     5.0  ...   \n",
      "8  2024   1  Abilene Christian  34  16  18  0.471  -4.12 -1.12    10.0  ...   \n",
      "9  2019   1  Abilene Christian  34  27   7  0.794  -1.91 -7.34    14.0  ...   \n",
      "\n",
      "   opp_ft  opp_fta  opp_ft%  opp_orb  opp_trb  opp_ast  opp_stl  opp_blk  \\\n",
      "0    17.1     24.1    0.708     9.84     32.4    13.10     6.61     4.13   \n",
      "1    16.4     23.8    0.688    10.10     35.9    12.10     5.81     4.03   \n",
      "2    16.8     23.7    0.707     8.58     33.3    12.10     5.16     3.16   \n",
      "3    15.4     23.1    0.666    10.10     35.1    13.60     6.14     3.03   \n",
      "4    16.4     23.2    0.707     9.78     34.6    11.60     6.41     2.84   \n",
      "5    17.2     23.5    0.734     8.74     33.4     9.58     6.81     3.68   \n",
      "6    17.4     24.0    0.725     9.08     34.5    11.20     5.53     3.61   \n",
      "7    16.4     22.9    0.715     8.00     33.6    12.50     5.57     3.27   \n",
      "8    15.4     22.5    0.685    10.10     36.8    12.40     6.68     3.32   \n",
      "9    13.6     18.9    0.722     8.68     32.3    10.50     5.65     2.71   \n",
      "\n",
      "   opp_tov  opp_pf  \n",
      "0     13.9    18.6  \n",
      "1     14.6    17.0  \n",
      "2     14.5    19.2  \n",
      "3     14.7    17.3  \n",
      "4     16.0    17.4  \n",
      "5     19.9    19.9  \n",
      "6     21.0    21.2  \n",
      "7     17.7    19.1  \n",
      "8     14.6    18.9  \n",
      "9     16.5    17.4  \n",
      "\n",
      "[10 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "basic_merged['school'] = basic_merged['school'].str.replace('NCAA', '', regex=False)\n",
    "basic_merged['school'] = basic_merged['school'].str.rstrip()\n",
    "\n",
    "\n",
    "if 'year' in basic_merged.columns:\n",
    "    basic_merged = basic_merged[['year'] + [col for col in basic_merged.columns if col != 'year']]\n",
    "\n",
    "\n",
    "print(basic_merged.head(10))\n",
    "basic_merged.to_csv(\"school_stats/basic_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  rk             school   g   w   l   w-l%    srs   sos  conf_w  ...  \\\n",
      "0  2014   1  Abilene Christian  31  11  20  0.355 -19.60 -4.12     2.0  ...   \n",
      "1  2015   1  Abilene Christian  31  10  21  0.323 -17.20 -6.34     4.0  ...   \n",
      "2  2016   1  Abilene Christian  31  13  18  0.419 -13.93 -7.53     8.0  ...   \n",
      "3  2017   1  Abilene Christian  29  13  16  0.448 -11.86 -7.10     7.0  ...   \n",
      "4  2018   1  Abilene Christian  32  16  16  0.500  -9.14 -6.82     8.0  ...   \n",
      "5  2020   1  Abilene Christian  31  20  11  0.645  -2.87 -6.87    15.0  ...   \n",
      "6  2022   1  Abilene Christian  36  25  11  0.694   2.25 -2.09    11.0  ...   \n",
      "7  2023   1  Abilene Christian  30  13  17  0.433  -2.79  0.90     5.0  ...   \n",
      "8  2024   1  Abilene Christian  34  16  18  0.471  -4.12 -1.12    10.0  ...   \n",
      "9  2019   1  Abilene Christian  34  27   7  0.794  -1.91 -7.34    14.0  ...   \n",
      "\n",
      "   opp_3par  opp_ts%  opp_trb%  opp_ast%  opp_stl%  opp_blk%  opp_efg%  \\\n",
      "0     0.320    0.558      49.8      53.6       9.7      12.0     0.518   \n",
      "1     0.327    0.573      55.4      50.1       8.8      11.6     0.539   \n",
      "2     0.292    0.565      51.0      47.5       7.3       8.6     0.527   \n",
      "3     0.373    0.553      52.9      55.5       8.9       8.8     0.522   \n",
      "4     0.374    0.540      50.3      48.1       8.9       7.5     0.499   \n",
      "5     0.335    0.535      49.9      44.5       9.4      10.0     0.482   \n",
      "6     0.405    0.555      51.8      51.5       7.6       9.4     0.507   \n",
      "7     0.339    0.576      50.9      51.4       7.8       8.3     0.538   \n",
      "8     0.319    0.547      52.3      47.3       9.3       7.8     0.514   \n",
      "9     0.333    0.529      49.7      47.3       8.3       7.4     0.488   \n",
      "\n",
      "   opp_tov%  opp_orb%  opp_ft/fga  \n",
      "0      17.8      30.2       0.323  \n",
      "1      19.2      33.4       0.325  \n",
      "2      18.2      26.9       0.313  \n",
      "3      18.5      30.1       0.287  \n",
      "4      19.5      28.5       0.298  \n",
      "5      24.6      27.8       0.346  \n",
      "6      25.6      29.6       0.351  \n",
      "7      22.2      26.5       0.322  \n",
      "8      17.8      29.7       0.273  \n",
      "9      21.5      27.3       0.267  \n",
      "\n",
      "[10 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "adv_merged['school'] = adv_merged['school'].str.replace('NCAA', '', regex=False)\n",
    "adv_merged['school'] = adv_merged['school'].str.rstrip()\n",
    "\n",
    "if 'year' in adv_merged.columns:\n",
    "    adv_merged = adv_merged[['year'] + [col for col in adv_merged.columns if col != 'year']]\n",
    "\n",
    "print(adv_merged.head(10))\n",
    "adv_merged.to_csv(\"school_stats/adv_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  rk             school   g   w   l   w-l%    srs   sos  conf_w  ...  \\\n",
      "0  2014   1  Abilene Christian  31  11  20  0.355 -19.60 -4.12     2.0  ...   \n",
      "1  2015   1  Abilene Christian  31  10  21  0.323 -17.20 -6.34     4.0  ...   \n",
      "2  2016   1  Abilene Christian  31  13  18  0.419 -13.93 -7.53     8.0  ...   \n",
      "3  2017   1  Abilene Christian  29  13  16  0.448 -11.86 -7.10     7.0  ...   \n",
      "4  2018   1  Abilene Christian  32  16  16  0.500  -9.14 -6.82     8.0  ...   \n",
      "5  2019   1  Abilene Christian  34  27   7  0.794  -1.91 -7.34    14.0  ...   \n",
      "6  2020   1  Abilene Christian  31  20  11  0.645  -2.87 -6.87    15.0  ...   \n",
      "7  2021   1  Abilene Christian  29  24   5  0.828   6.27 -6.37    13.0  ...   \n",
      "8  2022   1  Abilene Christian  36  25  11  0.694   2.25 -2.09    11.0  ...   \n",
      "9  2023   1  Abilene Christian  30  13  17  0.433  -2.79  0.90     5.0  ...   \n",
      "\n",
      "   opp_3par  opp_ts%  opp_trb%  opp_ast%  opp_stl%  opp_blk%  opp_efg%  \\\n",
      "0     0.320    0.558      49.8      53.6       9.7      12.0     0.518   \n",
      "1     0.327    0.573      55.4      50.1       8.8      11.6     0.539   \n",
      "2     0.292    0.565      51.0      47.5       7.3       8.6     0.527   \n",
      "3     0.373    0.553      52.9      55.5       8.9       8.8     0.522   \n",
      "4     0.374    0.540      50.3      48.1       8.9       7.5     0.499   \n",
      "5     0.333    0.529      49.7      47.3       8.3       7.4     0.488   \n",
      "6     0.335    0.535      49.9      44.5       9.4      10.0     0.482   \n",
      "7     0.349    0.498      48.5      49.8       9.1       9.9     0.458   \n",
      "8     0.405    0.555      51.8      51.5       7.6       9.4     0.507   \n",
      "9     0.339    0.576      50.9      51.4       7.8       8.3     0.538   \n",
      "\n",
      "   opp_tov%  opp_orb%  opp_ft/fga  \n",
      "0      17.8      30.2       0.323  \n",
      "1      19.2      33.4       0.325  \n",
      "2      18.2      26.9       0.313  \n",
      "3      18.5      30.1       0.287  \n",
      "4      19.5      28.5       0.298  \n",
      "5      21.5      27.3       0.267  \n",
      "6      24.6      27.8       0.346  \n",
      "7      24.7      26.8       0.262  \n",
      "8      25.6      29.6       0.351  \n",
      "9      22.2      26.5       0.322  \n",
      "\n",
      "[10 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(basic_merged, adv_merged, on=['school', 'year'], how='outer', suffixes=('', '_adv'))\n",
    "merged_data = merged_data.loc[:, ~merged_data.columns.str.endswith('_adv')]\n",
    "print(merged_data.head(10))\n",
    "merged_data.to_csv(\"school_stats/all_stats.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tournaments.to_csv(\"tournament_history/all_tournaments.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings.to_csv(\"team_ratings/all_ratings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings['School'] = all_ratings['School'].str.replace('Connecticut', 'UConn', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Connecticut', 'UConn', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('North Carolina', 'UNC', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('North Carolina', 'UNC', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace(\"Saint Mary's (CA)\", \"Saint Mary's\", regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace(\"Saint Mary's (CA)\", \"Saint Mary's\", regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Pittsburgh', 'Pitt', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Pittsburgh', 'Pitt', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Southern California', 'USC', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Southern California', 'USC', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace(\"Saint Joseph's\", \"St. Joseph's\", regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace(\"Saint Joseph's\", \"St. Joseph's\", regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Southern Methodist', 'SMU', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Southern Methodist', 'SMU', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Virginia Commonwealth', 'VCU', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Virginia Commonwealth', 'VCU', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace(\"Saint Peter's\", \"St. Peter's\", regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace(\"Saint Peter's\", \"St. Peter's\", regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Louisiana State', 'LSU', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Louisiana State', 'LSU', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Mississippi', 'Ole Miss', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Mississippi', 'Ole Miss', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Pennsylvania', 'Penn', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Pennsylvania', 'Penn', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('North Carolina State', 'NC State', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('North Carolina State', 'NC State', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('UC Irvine', 'UC-Irvine', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('UC Irvine', 'UC-Irvine', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('UC Santa Barbara', 'UCSB', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('UC Santa Barbara', 'UCSB', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Maryland-Baltimore County', 'UMBC', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Maryland-Baltimore County', 'UMBC', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('UC Davis', 'UC-Davis', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('UC Davis', 'UC-Davis', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('UC Riverside', 'UC-Riverside', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('UC Riverside', 'UC-Riverside', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('East Tennessee State', 'ETSU', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('East Tennessee State', 'ETSU', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Massachusetts', 'UMass', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Massachusetts', 'UMass', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('North Carolina State', 'NC State', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('North Carolina State', 'NC State', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Nevada-Las Vegas', 'UNLV', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Nevada-Las Vegas', 'UNLV', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Southern Mississippi', 'Southern Miss', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Southern Mississippi', 'Southern Miss', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Ole Miss State', 'Mississippi State', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Ole Miss State', 'Mississippi State', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Brigham Young', 'BYU', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Brigham Young', 'BYU', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('UNC Central', 'North Carolina Central', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('UNC Central', 'North Carolina Central', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('UNC A&T', 'North Carolina A&T', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('UNC A&T', 'North Carolina A&T', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Southern Ole Miss', 'Southern Miss', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Southern Ole Miss', 'Southern Miss', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Long Island University', 'LIU', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Long Island University', 'LIU', regex=False)\n",
    "\n",
    "all_ratings['School'] = all_ratings['School'].str.replace('Central UConn', 'Central Connecticut', regex=False)\n",
    "merged_data['school'] = merged_data['school'].str.replace('Central UConn', 'Central Connecticut', regex=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year   rk             school   g   w   l   w-l%    srs   sos  conf_w  \\\n",
      "5362  1993  151  Mississippi State  29  13  16  0.448   1.31  6.72     5.0   \n",
      "5363  1994  152  Mississippi State  29  18  11  0.621  10.77  7.48     9.0   \n",
      "5364  1995  153  Mississippi State  30  22   8  0.733  17.28  8.48    12.0   \n",
      "5365  1996  155  Mississippi State  34  26   8  0.765  16.19  8.72    10.0   \n",
      "5366  1997  155  Mississippi State  30  12  18  0.400   1.98  6.98     6.0   \n",
      "5367  1998  156  Mississippi State  30  15  15  0.500   7.75  5.12     4.0   \n",
      "5368  1999  159  Mississippi State  33  20  13  0.606   8.76  3.25     8.0   \n",
      "5369  2000  163  Mississippi State  30  14  16  0.467   7.12  5.29     5.0   \n",
      "5370  2001  163  Mississippi State  31  18  13  0.581  13.05  8.76     7.0   \n",
      "5371  2002  164  Mississippi State  35  27   8  0.771  14.43  7.34    10.0   \n",
      "5372  2003  167  Mississippi State  31  21  10  0.677  17.65  8.01     9.0   \n",
      "5373  2004  167  Mississippi State  30  26   4  0.867  16.78  6.08    14.0   \n",
      "5374  2005  168  Mississippi State  34  23  11  0.676  12.55  6.05     9.0   \n",
      "5375  2006  169  Mississippi State  30  15  15  0.500   5.16  5.66     5.0   \n",
      "5376  2007  170  Mississippi State  35  21  14  0.600  15.31  6.91     8.0   \n",
      "5377  2008  171  Mississippi State  34  23  11  0.676  13.42  5.74    12.0   \n",
      "5378  2009  173  Mississippi State  36  23  13  0.639   9.10  4.62     9.0   \n",
      "5379  2010  173  Mississippi State  36  24  12  0.667  12.55  4.60     9.0   \n",
      "5380  2011  173  Mississippi State  31  17  14  0.548   3.38  3.77     9.0   \n",
      "5381  2012  172  Mississippi State  33  21  12  0.636   9.13  4.86     8.0   \n",
      "5382  2013  172  Mississippi State  32  10  22  0.313  -4.52  4.36     4.0   \n",
      "5383  2014  176  Mississippi State  33  14  19  0.424  -0.86  2.75     3.0   \n",
      "5384  2015  176  Mississippi State  32  13  19  0.406   2.53  4.72     6.0   \n",
      "5385  2016  176  Mississippi State  31  14  17  0.452   8.18  6.02     7.0   \n",
      "5386  2017  176  Mississippi State  32  16  16  0.500   7.12  5.90     6.0   \n",
      "5387  2018  176  Mississippi State  37  25  12  0.676  11.71  6.82     9.0   \n",
      "5388  2019  177  Mississippi State  34  23  11  0.676  15.96  9.07    10.0   \n",
      "5389  2020  178  Mississippi State  31  20  11  0.645  12.21  6.96    11.0   \n",
      "5390  2021  172  Mississippi State  33  18  15  0.545   9.24  6.79     8.0   \n",
      "5391  2022  179  Mississippi State  34  18  16  0.529  11.83  7.60     8.0   \n",
      "5392  2023  181  Mississippi State  34  21  13  0.618  11.43  6.69     8.0   \n",
      "5393  2024  181  Mississippi State  35  21  14  0.600  14.19  9.16     8.0   \n",
      "\n",
      "      ...  opp_3par  opp_ts%  opp_trb%  opp_ast%  opp_stl%  opp_blk%  \\\n",
      "5362  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5363  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5364  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5365  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5366  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5367  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5368  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5369  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5370  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5371  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5372  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5373  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5374  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5375  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5376  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5377  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5378  ...       NaN      NaN       NaN       NaN       NaN       NaN   \n",
      "5379  ...     0.318    0.468      48.7      48.2       9.6       9.6   \n",
      "5380  ...     0.359    0.503      50.5      44.9       9.8       8.9   \n",
      "5381  ...     0.307    0.510      49.9      41.6       9.5       7.4   \n",
      "5382  ...     0.365    0.524      55.4      56.6      12.3      13.4   \n",
      "5383  ...     0.359    0.543      51.7      51.4       9.4       8.9   \n",
      "5384  ...     0.374    0.506      48.1      52.3      10.7      10.4   \n",
      "5385  ...     0.339    0.524      51.1      48.9       9.0       9.3   \n",
      "5386  ...     0.341    0.522      51.1      47.1       7.2       9.5   \n",
      "5387  ...     0.382    0.510      48.6      49.4       7.9       8.6   \n",
      "5388  ...     0.366    0.536      47.2      50.6       8.5      10.1   \n",
      "5389  ...     0.362    0.519      44.9      50.5      10.5       7.5   \n",
      "5390  ...     0.410    0.504      45.0      59.2      10.5       9.6   \n",
      "5391  ...     0.417    0.528      45.7      57.9      10.5       8.1   \n",
      "5392  ...     0.438    0.496      46.9      58.2       9.6       8.1   \n",
      "5393  ...     0.412    0.521      46.1      48.6      10.6      10.6   \n",
      "\n",
      "      opp_efg%  opp_tov%  opp_orb%  opp_ft/fga  \n",
      "5362       NaN       NaN       NaN         NaN  \n",
      "5363       NaN       NaN       NaN         NaN  \n",
      "5364       NaN       NaN       NaN         NaN  \n",
      "5365       NaN       NaN       NaN         NaN  \n",
      "5366       NaN       NaN       NaN         NaN  \n",
      "5367       NaN       NaN       NaN         NaN  \n",
      "5368       NaN       NaN       NaN         NaN  \n",
      "5369       NaN       NaN       NaN         NaN  \n",
      "5370       NaN       NaN       NaN         NaN  \n",
      "5371       NaN       NaN       NaN         NaN  \n",
      "5372       NaN       NaN       NaN         NaN  \n",
      "5373       NaN       NaN       NaN         NaN  \n",
      "5374       NaN       NaN       NaN         NaN  \n",
      "5375       NaN       NaN       NaN         NaN  \n",
      "5376       NaN       NaN       NaN         NaN  \n",
      "5377       NaN       NaN       NaN         NaN  \n",
      "5378       NaN       NaN       NaN         NaN  \n",
      "5379     0.440      14.1      30.3       0.165  \n",
      "5380     0.477      13.5      32.4       0.181  \n",
      "5381     0.488      13.8      30.6       0.160  \n",
      "5382     0.499      18.8      39.8       0.178  \n",
      "5383     0.511      17.6      31.5       0.235  \n",
      "5384     0.478      16.2      30.9       0.231  \n",
      "5385     0.489      15.7      32.8       0.250  \n",
      "5386     0.481      17.0      30.2       0.269  \n",
      "5387     0.481      16.9      30.4       0.199  \n",
      "5388     0.503      17.0      29.4       0.230  \n",
      "5389     0.481      14.9      28.3       0.232  \n",
      "5390     0.471      15.1      27.5       0.185  \n",
      "5391     0.496      17.3      25.7       0.205  \n",
      "5392     0.462      18.9      28.6       0.197  \n",
      "5393     0.480      16.0      27.8       0.239  \n",
      "\n",
      "[32 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_data[merged_data['school'] == 'Mississippi State'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  region         round             team1  seed1  score1               team2  \\\n",
      "0   East   First Round             UConn      1      91             Stetson   \n",
      "1   East   First Round  Florida Atlantic      8      65        Northwestern   \n",
      "2   East   First Round   San Diego State      5      69                 UAB   \n",
      "3   East   First Round            Auburn      4      76                Yale   \n",
      "4   East   First Round               BYU      6      67            Duquesne   \n",
      "5   East   First Round          Illinois      3      85      Morehead State   \n",
      "6   East   First Round  Washington State      7      66               Drake   \n",
      "7   East   First Round        Iowa State      2      82  South Dakota State   \n",
      "8   East  Second Round             UConn      1      75        Northwestern   \n",
      "9   East  Second Round   San Diego State      5      85                Yale   \n",
      "\n",
      "   seed2  score2            winner  year  ...  Pts_team2  Opp_team2  \\\n",
      "0     16      52             UConn  2024  ...       76.8       73.3   \n",
      "1      9      77      Northwestern  2024  ...       73.3       69.1   \n",
      "2     12      65   San Diego State  2024  ...       77.5       75.1   \n",
      "3     13      78              Yale  2024  ...       74.7       67.5   \n",
      "4     11      71          Duquesne  2024  ...       70.6       66.7   \n",
      "5     14      69          Illinois  2024  ...       75.3       63.4   \n",
      "6     10      61  Washington State  2024  ...       79.9       70.4   \n",
      "7     15      65        Iowa State  2024  ...       76.4       71.1   \n",
      "8      9      58             UConn  2024  ...       73.3       69.1   \n",
      "9     13      57   San Diego State  2024  ...       74.7       67.5   \n",
      "\n",
      "   MOV_team2  SOS_team2  OSRS_team2  DSRS_team2  SRS_team2  ORtg_team2  \\\n",
      "0       3.46      -3.24       -0.77       -4.31      -5.09      107.27   \n",
      "1       4.26       8.50        4.74        8.03      12.77      116.38   \n",
      "2       2.40       3.73        5.85       -0.71       5.14      111.80   \n",
      "3       7.24       0.41        0.18        4.45       4.63      108.51   \n",
      "4       3.89       4.68       -0.49        7.84       7.35      107.08   \n",
      "5      11.86      -5.52       -3.49        4.01       0.51      106.08   \n",
      "6       9.54       1.84        8.12        2.96      11.08      115.20   \n",
      "7       5.29      -2.70        1.36       -0.84       0.52      107.29   \n",
      "8       4.26       8.50        4.74        8.03      12.77      116.38   \n",
      "9       7.24       0.41        0.18        4.45       4.63      108.51   \n",
      "\n",
      "   DRtg_team2  NRtg_team2  \n",
      "0      114.59       -7.33  \n",
      "1       97.73       18.65  \n",
      "2      104.45        7.35  \n",
      "3      101.46        7.05  \n",
      "4       96.48       10.61  \n",
      "5      104.04        2.04  \n",
      "6       99.18       16.02  \n",
      "7      105.79        1.50  \n",
      "8       97.73       18.65  \n",
      "9      101.46        7.05  \n",
      "\n",
      "[10 rows x 188 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge team1 stats\n",
    "merged_final = pd.merge(all_tournaments, merged_data, \n",
    "                        left_on=['team1', 'year'], right_on=['school', 'year'], \n",
    "                        how='left', suffixes=('', '_team1'))\n",
    "\n",
    "merged_final = pd.merge(merged_final, all_ratings, \n",
    "                        left_on=['team1', 'year'], right_on=['School', 'year'], \n",
    "                        how='left', suffixes=('', '_team1'))\n",
    "\n",
    "# Merge team2 stats\n",
    "merged_final = pd.merge(merged_final, merged_data, \n",
    "                        left_on=['team2', 'year'], right_on=['school', 'year'], \n",
    "                        how='left', suffixes=('', '_team2'))\n",
    "\n",
    "merged_final = pd.merge(merged_final, all_ratings, \n",
    "                        left_on=['team2', 'year'], right_on=['School', 'year'], \n",
    "                        how='left', suffixes=('', '_team2'))\n",
    "\n",
    "# Drop duplicate columns that resulted from merging\n",
    "merged_final = merged_final.drop(columns=['school', 'School'])\n",
    "\n",
    "# Save the final merged dataset\n",
    "merged_final.to_csv(\"school_stats/final_merged_data.csv\", index=False)\n",
    "\n",
    "# Preview the output\n",
    "print(merged_final.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                team1        team2\n",
      "726          Kentucky         ETSU\n",
      "727             Texas  Wake Forest\n",
      "728            Temple      Cornell\n",
      "729         Wisconsin      Wofford\n",
      "730         Marquette   Washington\n",
      "...               ...          ...\n",
      "1984         NC State      Alabama\n",
      "1985  St. John's (NY)     NC State\n",
      "1986        Villanova      Memphis\n",
      "1987  St. John's (NY)   Georgetown\n",
      "1988        Villanova   Georgetown\n",
      "\n",
      "[1263 rows x 2 columns]\n",
      "team1           team2         \n",
      "UNC             Michigan State    4\n",
      "UConn           Duke              4\n",
      "Kentucky        Utah              4\n",
      "UNC             Arkansas          4\n",
      "Texas           Purdue            3\n",
      "Syracuse        Kansas            3\n",
      "Duke            Kansas            3\n",
      "Arizona         Oklahoma          3\n",
      "UNC             Louisville        3\n",
      "Oklahoma State  Georgia Tech      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_teams = merged_final[merged_final.isnull().any(axis=1)][['team1', 'team2']]\n",
    "print(null_teams)\n",
    "\n",
    "most_common_null_teams = null_teams.value_counts().head(10)\n",
    "print(most_common_null_teams)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
